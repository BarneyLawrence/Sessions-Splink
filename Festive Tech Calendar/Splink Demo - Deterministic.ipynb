{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "pip install splink"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Splink Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from splink.spark.jar_location import similarity_jar_location\r\n",
        "\r\n",
        "from pyspark  import SparkContext, SparkConf\r\n",
        "from pyspark.sql import SparkSession, types\r\n",
        "from pyspark.sql.types import DoubleType, StringType\r\n",
        "from pyspark.sql.functions import substring\r\n",
        "import splink.spark.comparison_library as cl\r\n",
        "import splink.spark.comparison_level_library as cll\r\n",
        "import splink.spark.comparison_template_library as ctl\r\n",
        "import splink.spark.blocking_rule_library as brl\r\n",
        "from splink.comparison import Comparison\r\n",
        "from splink.spark.linker import SparkLinker\r\n",
        "import os\r\n",
        "import pprint\r\n",
        "\r\n",
        "conf = SparkConf()\r\n",
        "\r\n",
        "\r\n",
        "conf.set(\"spark.driver.memory\", \"64g\")\r\n",
        "conf.set(\"spark.kryoserializer.buffer.max\",\"1024m\")\r\n",
        "conf.set(\"spark.default.parallelism\", \"40\")\r\n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\", \"40\")\r\n",
        "\r\n",
        "\r\n",
        "# Adds custom similarity functions, which are bundled with Splink\r\n",
        "# documented here: https://github.com/moj-analytical-services/splink_scalaudfs\r\n",
        "# The jar file needs to be downloaded from the above and uploaded to the synapse workspace\r\n",
        "path = similarity_jar_location()\r\n",
        "\r\n",
        "#conf.set('spark.driver.extraClassPath', path) #added by ash\r\n",
        "conf.set(\"spark.jars\", path)\r\n",
        "\r\n",
        "sc = SparkContext.getOrCreate(conf=conf)\r\n",
        "\r\n",
        "spark = SparkSession(sc)\r\n",
        "spark.sparkContext.setCheckpointDir(\"./tmp_checkpoints\")\r\n",
        "\r\n",
        "os.makedirs(\"/tmp/Temp\", exist_ok=True)\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Data Matching Function Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "spark.udf.registerJavaFunction('jaro_winkler', 'uk.gov.moj.dash.linkage.JaroWinklerSimilarity',DoubleType())                              \r\n",
        "spark.udf.registerJavaFunction('jaccard_sim', 'uk.gov.moj.dash.linkage.JaccardSimilarity',DoubleType())                          \r\n",
        "spark.udf.registerJavaFunction('cosine_distance', 'uk.gov.moj.dash.linkage.CosineDistance',DoubleType())\r\n",
        "spark.udf.registerJavaFunction('sqlEscape', 'uk.gov.moj.dash.linkage.sqlEscape',StringType())                        \r\n",
        "spark.udf.registerJavaFunction('levdamerau_distance', 'uk.gov.moj.dash.linkage.LevDamerauDistance',DoubleType())   \r\n",
        "spark.udf.registerJavaFunction('jaro_sim', 'uk.gov.moj.dash.linkage.JaroSimilarity',DoubleType())   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Drive Mounting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#if not(any(mount.mountPoint == \"/lake\" for mount in mssparkutils.fs.mounts())):\r\n",
        "#    mssparkutils.fs.mount(\r\n",
        "#        \"abfss://synapse@sasynapsesplinkproduks01.dfs.core.windows.net\",\r\n",
        "#        \"/lake\",\r\n",
        "#        {\"linkedService\" : \"synw-synapsesplink-prod-uks-01-WorkspaceDefaultStorage\"}\r\n",
        "#    )\r\n",
        "\r\n",
        "#    MountPath = \"synfs:/\" + mssparkutils.env.getJobId() + \"/lake/splink/\"\r\n",
        "#    print(MountPath)\r\n",
        "#else:\r\n",
        "#    print(MountPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Import Demo Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#https://moj-analytical-services.github.io/splink/datasets.html\r\n",
        "\r\n",
        "from splink.datasets import splink_datasets\r\n",
        "\r\n",
        "#df = splink_datasets.fake_1000\r\n",
        "#columns: ['unique_id', 'first_name', 'surname', 'dob', 'city', 'email', 'cluster']\r\n",
        "\r\n",
        "pdf = splink_datasets.historical_50k\r\n",
        "df = spark.createDataFrame(pdf)\r\n",
        "#columns: ['unique_id','cluster','full_name','first_and_surname','first_name','surname','dob','birth_place','postcode_fake','gender','occupation']\r\n",
        "\r\n",
        "#list(df.columns.values)\r\n",
        "#pdf.head(5)\r\n",
        "#df.limit(5).show()\r\n",
        "\r\n",
        "df.count()\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Linkage settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "settings = {\r\n",
        "    \"link_type\": \"dedupe_only\",\r\n",
        "    \"blocking_rules_to_generate_predictions\": [\r\n",
        "        #brl.block_on([\"surname\"]),\r\n",
        "        brl.block_on([\"first_name\",\"surname\",\"dob\"]),\r\n",
        "        brl.block_on([\"first_name\",\"surname\",\"postcode_fake\"]),\r\n",
        "        brl.block_on([\"first_name\",\"dob\",\"postcode_fake\"]),\r\n",
        "        brl.block_on([\"surname\",\"dob\",\"postcode_fake\"]),\r\n",
        "    ],\r\n",
        "    \"retain_matching_columns\": True,\r\n",
        "    \"retain_intermediate_calculation_columns\": True,\r\n",
        "    #\"additional_columns_to_retain\": [\"Street\",\"Locality\",\"Town\",\"County\"]\r\n",
        "    #\"em_convergence\": 0.001\r\n",
        "}\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create the linkage model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "linker = SparkLinker(df, settings)\r\n",
        "\r\n",
        "linker.profile_columns(\r\n",
        "    [\"first_name\", \"surname\", \"postcode_fake\", \"substr(dob, 1,4)\"], top_n=10, bottom_n=5\r\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Number of comparisons generated by deterministic rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "linker.cumulative_num_comparisons_from_blocking_rules_chart()\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Generate comparisons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "df_predict = linker.deterministic_link()\r\n",
        "df_predict.as_pandas_dataframe().head()\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Cluster to generate distinct output list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "clusters = linker.cluster_pairwise_predictions_at_threshold(df_predict, threshold_match_probability=1)\r\n",
        "#cdf = clusters.as_pandas_dataframe\r\n",
        "#clusters.as_pandas_dataframe(limit=5)\r\n",
        "spark.createDataFrame(clusters.as_pandas_dataframe()).createOrReplaceTempView(\"clusters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "select *\r\n",
        "from clusters\r\n",
        "order by cluster_id\r\n",
        "limit 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "select count(1)\r\n",
        "from\r\n",
        "(select distinct cluster_id\r\n",
        "from clusters)\r\n",
        "--limit 10"
      ]
    }
  ]
}